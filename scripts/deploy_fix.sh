# #!/bin/bash
# # ä¿®å¤æ‰€æœ‰prompt_builderæ–¹æ³•çš„å¼‚æ­¥è°ƒç”¨é—®é¢˜

# echo "ğŸ”§ ä¿®å¤æ‰€æœ‰prompt_builderæ–¹æ³•çš„å¼‚æ­¥è°ƒç”¨é—®é¢˜"
# echo "============================================================"

# cd /home/fishros/ai-ros

# # 1. å¤‡ä»½å½“å‰æ–‡ä»¶
# echo "1. å¤‡ä»½å½“å‰æ–‡ä»¶..."
# timestamp=$(date +%Y%m%d_%H%M%S)
# cp "app/services/query_service.py" "app/services/query_service.py.backup_async_fix_${timestamp}"

# # 2. ä¿®å¤query_service.pyä¸­çš„æ‰€æœ‰å¼‚æ­¥è°ƒç”¨é—®é¢˜
# echo "2. ä¿®å¤query_service.py..."
# cat > "app/services/query_service.py" << 'EOF'
# """
# æ›´æ–°æŸ¥è¯¢æœåŠ¡ä»¥é›†æˆæ•…éšœè¯Šæ–­æ ‘åŠŸèƒ½
# """
# from typing import List, Dict, Any, Optional
# import asyncio
# from .embedding_service import EmbeddingService
# from .llm_service import LLMService
# from ..repositories.database import DatabaseRepository
# from ..services.runtime_context import RuntimeContextBuilder
# from ..services.prompt_builder_with_diagnosis import RAGPromptBuilder
# from ..services.diagnostic_service import DiagnosticService
# from ..models.schemas import RuntimeState, QueryWithRuntimeRequest

# class QueryService:
#     def __init__(self, embedding_service: EmbeddingService, 
#                  database_repo: DatabaseRepository,
#                  llm_service: LLMService):
#         self.embedding = embedding_service
#         self.db = database_repo
#         self.llm = llm_service
#         self.runtime_builder = RuntimeContextBuilder()
#         self.prompt_builder = RAGPromptBuilder()
#         self.diagnostic_service = DiagnosticService()
    
#     async def query_with_runtime(self, request: QueryWithRuntimeRequest) -> Dict[str, Any]:
#         """
#         æ‰§è¡Œå¸¦æœ‰è¿è¡Œæ—¶çŠ¶æ€çš„RAGæŸ¥è¯¢ï¼ˆå¢å¼ºç‰ˆï¼Œé›†æˆè¯Šæ–­æ ‘ï¼‰
#         """
#         try:
#             # ç”ŸæˆæŸ¥è¯¢å‘é‡
#             query_vectors = await self.embedding.embed([request.query])
#             query_vector = query_vectors[0]
            
#             # æ„å»ºè¿‡æ»¤æ¡ä»¶
#             filter_dict = None
#             if request.runtime_state and request.runtime_state.robot_id:
#                 filter_dict = {"robot": request.runtime_state.robot_id}
            
#             # æ‰§è¡Œå‘é‡æœç´¢
#             search_results = await self.db.search_similar_chunks(
#                 query_embedding=query_vector,
#                 top_k=request.top_k,
#                 filter_dict=filter_dict
#             )
            
#             # å¦‚æœæœ‰é”™è¯¯ä»£ç ï¼Œé¢å¤–æœç´¢é”™è¯¯ç›¸å…³æ–‡æ¡£
#             error_results = []
#             if request.runtime_state and request.runtime_state.errors:
#                 error_search_terms = self.runtime_builder.extract_error_codes_for_search(
#                     request.runtime_state.errors
#                 )
                
#                 if error_search_terms:
#                     error_vectors = await self.embedding.embed(error_search_terms[:3])  # é™åˆ¶æ•°é‡
#                     for error_vector in error_vectors:
#                         more_results = await self.db.search_similar_chunks(
#                             query_embedding=error_vector,
#                             top_k=2,
#                             filter_dict={"category": "ros_safety"}
#                         )
#                         error_results.extend(more_results)
            
#             # åˆå¹¶ç»“æœ
#             all_results = self._merge_and_deduplicate_results(search_results, error_results)
            
#             # æ„å»ºè¿è¡Œæ—¶ä¸Šä¸‹æ–‡
#             runtime_context = ""
#             if request.runtime_state:
#                 runtime_context = self.runtime_builder.build_runtime_context(request.runtime_state)
            
#             # ä½¿ç”¨å¢å¼ºçš„æç¤ºè¯æ„å»ºå™¨ç”Ÿæˆå›ç­”
#             answer = await self._generate_llm_answer_with_diagnosis(
#                 query=request.query,
#                 search_results=all_results,
#                 runtime_context=runtime_context,
#                 runtime_state=request.runtime_state,
#                 error_codes=request.runtime_state.errors if request.runtime_state else None
#             )
            
#             # æå–æºä¿¡æ¯
#             sources = self._extract_sources(all_results)
            
#             # è®¡ç®—ç½®ä¿¡åº¦
#             confidence = all_results[0]["score"] if all_results else 0.0
            
#             # ä¿å­˜æŸ¥è¯¢å†å²
#             await self.db.save_query_history(
#                 query=f"[Diagnosis] {request.query}",
#                 answer=answer,
#                 sources=sources,
#                 confidence=confidence
#             )
            
#             # å¦‚æœæ¶‰åŠé”™è¯¯è¯Šæ–­ï¼Œæ·»åŠ è¯Šæ–­æ‘˜è¦
#             diagnostic_summary = None
#             if request.runtime_state and request.runtime_state.errors:
#                 try:
#                     diagnosis = await self.diagnostic_service.diagnose_multiple_errors(
#                         request.runtime_state.errors,
#                         request.runtime_state
#                     )
#                     diagnostic_summary = {
#                         "error_count": len(request.runtime_state.errors),
#                         "primary_error": diagnosis.get("primary_error"),
#                         "severity": diagnosis.get("primary_severity"),
#                         "most_likely_cause": diagnosis.get("combined_causes", [{}])[0].get("description", "Unknown") if diagnosis.get("combined_causes") else "Unknown"
#                     }
#                 except Exception as e:
#                     diagnostic_summary = {"error": str(e)}
            
#             return {
#                 "answer": answer,
#                 "sources": sources,
#                 "confidence": confidence,
#                 "result_count": len(all_results),
#                 "runtime_context_used": runtime_context if request.runtime_state else None,
#                 "diagnostic_summary": diagnostic_summary
#             }
            
#         except Exception as e:
#             import traceback
#             traceback.print_exc()
#             return {
#                 "answer": f"Error processing query with runtime state: {str(e)}",
#                 "sources": [],
#                 "confidence": 0.0,
#                 "result_count": 0
#             }
    
#     async def _generate_llm_answer_with_diagnosis(
#         self, 
#         query: str, 
#         search_results: List[Dict[str, Any]], 
#         runtime_context: str = "",
#         runtime_state: Optional[RuntimeState] = None,
#         error_codes: Optional[List[str]] = None
#     ) -> str:
#         """ä½¿ç”¨LLMåŸºäºæœç´¢ç»“æœå’Œè¯Šæ–­æ ‘ç”Ÿæˆå›ç­”"""
#         if not search_results and not error_codes:
#             return "I don't have enough information to answer this question based on the available documentation."
        
#         # æå–ä¸Šä¸‹æ–‡æ–‡æœ¬
#         contexts = [result["metadata"]["text"] for result in search_results]
        
#         # åˆ¤æ–­æ˜¯å¦ä¸ºé”™è¯¯è¯Šæ–­æŸ¥è¯¢
#         is_error_diagnosis = error_codes is not None and len(error_codes) > 0
        
#         # æ„å»ºæç¤ºè¯ - ä¿®å¤ï¼šæ‰€æœ‰prompt_builderæ–¹æ³•éƒ½ä¸æ˜¯å¼‚æ­¥çš„ï¼Œæ‰€ä»¥ä¸éœ€è¦await
#         if is_error_diagnosis:
#             prompt = self.prompt_builder.build_diagnostic_prompt(
#                 query=query,
#                 contexts=contexts,
#                 runtime_context=runtime_context,
#                 error_codes=error_codes,
#                 runtime_state=runtime_state
#             )
#         else:
#             prompt = self.prompt_builder.build_rag_prompt(
#                 query=query,
#                 contexts=contexts,
#                 runtime_context=runtime_context
#             )
        
#         # ç”Ÿæˆå›ç­” - è¿™ä¸ªæ˜¯å¼‚æ­¥çš„
#         answer = await self.llm.generate_answer_from_prompt(prompt)
        
#         # å¦‚æœæ²¡æœ‰è‡ªåŠ¨æ·»åŠ å¼•ç”¨ï¼Œæ‰‹åŠ¨æ·»åŠ 
#         if search_results and "Context" not in answer and "Source" not in answer:
#             ref_text = " ".join([f"[Context {i+1}]" for i in range(len(search_results))])
#             answer = f"{answer}\n\n**Documentation References**: {ref_text}"
        
#         return answer
    
#     async def diagnostic_query(self, error_codes: List[str], runtime_state: RuntimeState) -> Dict[str, Any]:
#         """
#         ä¸“é—¨çš„è¯Šæ–­æŸ¥è¯¢ï¼ˆç›´æ¥ä½¿ç”¨æ•…éšœæ ‘ï¼Œä¸è¿›è¡Œå‘é‡æœç´¢ï¼‰
        
#         Args:
#             error_codes: é”™è¯¯ä»£ç åˆ—è¡¨
#             runtime_state: è¿è¡Œæ—¶çŠ¶æ€
            
#         Returns:
#             è¯Šæ–­ç»“æœ
#         """
#         try:
#             # ç”Ÿæˆè¯Šæ–­è®¡åˆ’
#             diagnosis_plan = await self.diagnostic_service.generate_diagnosis_plan(
#                 error_codes, runtime_state
#             )
            
#             # è·å–ç›¸å…³çš„æ–‡æ¡£ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
#             if error_codes:
#                 # æœç´¢é”™è¯¯ç›¸å…³æ–‡æ¡£
#                 error_search_terms = self.runtime_builder.extract_error_codes_for_search(error_codes)
#                 if error_search_terms:
#                     error_vectors = await self.embedding.embed(error_search_terms[:2])
#                     search_results = []
#                     for vector in error_vectors:
#                         results = await self.db.search_similar_chunks(
#                             query_embedding=vector,
#                             top_k=2,
#                             filter_dict={"category": "ros_safety"}
#                         )
#                         search_results.extend(results)
                    
#                     contexts = [result["metadata"]["text"] for result in search_results]
#                 else:
#                     contexts = []
#             else:
#                 contexts = []
            
#             # æ„å»ºè¿è¡Œæ—¶ä¸Šä¸‹æ–‡
#             runtime_context = self.runtime_builder.build_runtime_context(runtime_state)
            
#             # ä½¿ç”¨è¯Šæ–­ä¸“ç”¨æç¤ºè¯ç”Ÿæˆè¯¦ç»†åˆ†æ
#             if contexts:
#                 # ä¿®å¤ï¼šbuild_error_analysis_promptä¸æ˜¯å¼‚æ­¥æ–¹æ³•
#                 prompt = self.prompt_builder.build_error_analysis_prompt(
#                     error_codes=error_codes,
#                     contexts=contexts,
#                     runtime_context=runtime_context,
#                     runtime_state=runtime_state
#                 )
                
#                 detailed_analysis = await self.llm.generate_answer_from_prompt(prompt)
#             else:
#                 detailed_analysis = "No additional documentation context available for detailed analysis."
            
#             # ä¿å­˜æŸ¥è¯¢å†å²
#             await self.db.save_query_history(
#                 query=f"[Diagnosis] Errors: {', '.join(error_codes)}",
#                 answer=detailed_analysis[:500],  # åªä¿å­˜æ‘˜è¦
#                 sources=[],
#                 confidence=0.8  # è¯Šæ–­æ ‘æœ‰è¾ƒé«˜çš„ç½®ä¿¡åº¦
#             )
            
#             return {
#                 "status": "diagnosed",
#                 "diagnosis_plan": diagnosis_plan,
#                 "detailed_analysis": detailed_analysis,
#                 "error_codes": error_codes,
#                 "robot_id": runtime_state.robot_id,
#                 "timestamp": asyncio.get_event_loop().time()
#             }
            
#         except Exception as e:
#             import traceback
#             traceback.print_exc()
#             return {
#                 "status": "error",
#                 "message": f"Diagnostic query failed: {str(e)}",
#                 "error_codes": error_codes,
#                 "robot_id": runtime_state.robot_id,
#                 "timestamp": 0.0
#             }
    
#     def _merge_and_deduplicate_results(self, primary_results: List[Dict], secondary_results: List[Dict]) -> List[Dict]:
#         """åˆå¹¶å¹¶å»é‡æœç´¢ç»“æœ"""
#         seen_ids = set()
#         merged = []
        
#         for result in primary_results:
#             result_id = result.get("id")
#             if result_id and result_id not in seen_ids:
#                 seen_ids.add(result_id)
#                 merged.append(result)
        
#         for result in secondary_results:
#             result_id = result.get("id")
#             if result_id and result_id not in seen_ids:
#                 seen_ids.add(result_id)
#                 merged.append(result)
        
#         merged.sort(key=lambda x: x.get("score", 0), reverse=True)
#         return merged[:10]
    
#     async def query(self, query_text: str, top_k: int = 5, 
#                    filter_category: Optional[str] = None) -> Dict[str, Any]:
#         """
#         åŸå§‹æŸ¥è¯¢æ–¹æ³•ï¼ˆå‘åå…¼å®¹ï¼‰
#         """
#         try:
#             query_vectors = await self.embedding.embed([query_text])
#             query_vector = query_vectors[0]
            
#             filter_dict = None
#             if filter_category:
#                 filter_dict = {"category": filter_category}
            
#             search_results = await self.db.search_similar_chunks(
#                 query_embedding=query_vector,
#                 top_k=top_k,
#                 filter_dict=filter_dict
#             )
            
#             contexts = [result["metadata"]["text"] for result in search_results]
#             # ä¿®å¤ï¼šbuild_rag_promptä¸æ˜¯å¼‚æ­¥æ–¹æ³•
#             prompt = self.prompt_builder.build_rag_prompt(
#                 query=query_text,
#                 contexts=contexts,
#                 runtime_context=""
#             )
            
#             answer = await self.llm.generate_answer_from_prompt(prompt)
            
#             sources = self._extract_sources(search_results)
#             confidence = search_results[0]["score"] if search_results else 0.0
            
#             await self.db.save_query_history(
#                 query=query_text,
#                 answer=answer,
#                 sources=sources,
#                 confidence=confidence
#             )
            
#             return {
#                 "answer": answer,
#                 "sources": sources,
#                 "confidence": confidence,
#                 "result_count": len(search_results)
#             }
            
#         except Exception as e:
#             import traceback
#             traceback.print_exc()
#             return {
#                 "answer": f"Error processing query: {str(e)}",
#                 "sources": [],
#                 "confidence": 0.0,
#                 "result_count": 0
#             }
    
#     async def get_query_history(self, limit: int = 50) -> List[Dict[str, Any]]:
#         """è·å–æŸ¥è¯¢å†å²"""
#         return await self.db.get_query_history(limit)
    
#     def _extract_sources(self, search_results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
#         """ä»æœç´¢ç»“æœä¸­æå–æºä¿¡æ¯"""
#         sources = []
#         for i, result in enumerate(search_results):
#             metadata = result["metadata"]
#             sources.append({
#                 "id": result["id"],
#                 "text": metadata["text"][:150] + "..." if len(metadata["text"]) > 150 else metadata["text"],
#                 "category": metadata.get("category", "unknown"),
#                 "score": result["score"],
#                 "metadata": {k: v for k, v in metadata.items() if k != "text"}
#             })
#         return sources
    
#     async def get_available_diagnoses(self) -> Dict[str, Any]:
#         """è·å–å¯ç”¨çš„è¯Šæ–­ä¿¡æ¯"""
#         error_codes = self.diagnostic_service.get_available_error_codes()
        
#         # è·å–æ¯ä¸ªé”™è¯¯ä»£ç çš„ç®€è¦ä¿¡æ¯
#         diagnoses_info = []
#         for code in error_codes[:10]:  # é™åˆ¶æ•°é‡
#             tree = self.diagnostic_service.fault_trees.get(code)
#             if tree:
#                 diagnoses_info.append({
#                     "error_code": code,
#                     "description": tree.description,
#                     "category": tree.category,
#                     "severity": tree.severity,
#                     "cause_count": len(tree.causes)
#                 })
        
#         return {
#             "available_error_codes": error_codes,
#             "total_diagnoses": len(error_codes),
#             "diagnoses_info": diagnoses_info
#         }
# EOF

# echo "âœ… å·²ä¿®å¤query_service.pyä¸­çš„æ‰€æœ‰å¼‚æ­¥è°ƒç”¨é—®é¢˜"

# # 3. é‡å¯æœåŠ¡
# echo -e "\n3. é‡å¯æœåŠ¡..."
# pkill -f "uvicorn" 2>/dev/null || true
# sleep 2

# echo "   å¯åŠ¨æœåŠ¡..."
# nohup uvicorn app.main:app --reload --host 0.0.0.0 --port 8000 > /tmp/ros_docs_diag.log 2>&1 &
# PID=$!
# echo $PID > /tmp/ros_docs_diag.pid

# # 4. ç­‰å¾…æœåŠ¡å¯åŠ¨å¹¶æµ‹è¯•
# echo -e "\n4. ç­‰å¾…æœåŠ¡å¯åŠ¨..."
# sleep 5

echo "   æµ‹è¯•å¢å¼ºæŸ¥è¯¢åŠŸèƒ½:"
echo "   æµ‹è¯•1: å¸¦é”™è¯¯è¯Šæ–­çš„æŸ¥è¯¢"
curl -X POST http://localhost:8000/api/v1/ros/query-with-runtime \
  -H "Content-Type: application/json" \
  -d '{
    "query": "æœºå™¨äººå®‰å…¨åœæ­¢äº†æ€ä¹ˆåŠ",
    "top_k": 3,
    "runtime_state": {
      "robot_id": "test_robot",
      "errors": ["E201"]
    }
  }' | python3 -c "
import json, sys
try:
    data = json.load(sys.stdin)
    print('   å“åº”çŠ¶æ€: âœ…' if data.get('answer') and not data.get('answer').startswith('Error') else '   å“åº”çŠ¶æ€: âŒ')
    print('   å›ç­”é•¿åº¦:', len(data.get('answer', '')))
    print('   ç½®ä¿¡åº¦:', data.get('confidence', 0))
    print('   ç»“æœæ•°é‡:', data.get('result_count', 0))
    
    if data.get('diagnostic_summary'):
        summary = data['diagnostic_summary']
        print('   è¯Šæ–­æ‘˜è¦:')
        print('     â€¢ é”™è¯¯æ•°é‡:', summary.get('error_count', 'N/A'))
        print('     â€¢ ä¸»è¦é”™è¯¯:', summary.get('primary_error', 'N/A'))
        print('     â€¢ ä¸¥é‡æ€§:', summary.get('severity', 'N/A'))
    else:
        print('   è¯Šæ–­æ‘˜è¦: æ— ')
        
    # æ˜¾ç¤ºå›ç­”å‰100ä¸ªå­—ç¬¦
    answer = data.get('answer', '')
    if answer:
        preview = answer[:100] + ('...' if len(answer) > 100 else '')
        print('   å›ç­”é¢„è§ˆ:', preview)
        
except Exception as e:
    print('   âŒ è§£æå“åº”å¤±è´¥:', e)
"

echo ""
echo "   æµ‹è¯•2: è¯Šæ–­åˆ†æAPI"
curl -X POST http://localhost:8000/api/v1/diagnostics/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "error_codes": ["E201"],
    "runtime_state": {
      "robot_id": "test_robot",
      "errors": ["E201"],
      "active_topics": ["/scan", "/cmd_vel"],
      "parameters": {"emergency_stop": true}
    },
    "include_detailed_analysis": true
  }' | python3 -c "
import json, sys
try:
    data = json.load(sys.stdin)
    print('   å“åº”çŠ¶æ€:', data.get('status'))
    
    if data.get('status') == 'diagnosed':
        print('   âœ… è¯Šæ–­åˆ†ææˆåŠŸ!')
        plan = data.get('diagnosis_plan')
        if plan:
            print('   è¯Šæ–­è®¡åˆ’çŠ¶æ€:', plan.get('status'))
            if plan.get('check_steps'):
                print('   æ£€æŸ¥æ­¥éª¤:', len(plan['check_steps']), 'ä¸ª')
                for i, step in enumerate(plan['check_steps'][:2], 1):
                    print(f'     {i}. {step.get(\"description\", \"N/A\")[:40]}...')
        
        analysis = data.get('detailed_analysis')
        if analysis:
            print('   è¯¦ç»†åˆ†æé•¿åº¦:', len(analysis), 'å­—ç¬¦')
            print('   åˆ†æé¢„è§ˆ:', analysis[:80] + ('...' if len(analysis) > 80 else ''))
    elif data.get('status') == 'error':
        print('   âŒ è¯Šæ–­åˆ†æå¤±è´¥:', data.get('message', 'Unknown error'))
    else:
        print('   â„¹ï¸ æœªçŸ¥çŠ¶æ€:', data)
        
except Exception as e:
    print('   âŒ è§£æå“åº”å¤±è´¥:', e)
"

echo ""
echo "   æµ‹è¯•3: åŸºç¡€æŸ¥è¯¢åŠŸèƒ½"
curl -X POST http://localhost:8000/api/v1/ros/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "ä»€ä¹ˆæ˜¯ROSå®‰å…¨ç³»ç»Ÿ",
    "top_k": 2
  }' | python3 -c "
import json, sys
try:
    data = json.load(sys.stdin)
    print('   åŸºç¡€æŸ¥è¯¢çŠ¶æ€: âœ…' if data.get('answer') and not data.get('answer').startswith('Error') else '   åŸºç¡€æŸ¥è¯¢çŠ¶æ€: âŒ')
    print('   å›ç­”é•¿åº¦:', len(data.get('answer', '')))
    print('   ç½®ä¿¡åº¦:', data.get('confidence', 0))
    print('   ç»“æœæ•°é‡:', data.get('result_count', 0))
except Exception as e:
    print('   âŒ è§£æå“åº”å¤±è´¥:', e)
"

echo ""
echo "============================================================"
echo "ğŸ‰ ä¿®å¤å®Œæˆï¼"
echo ""
echo "ğŸ“‹ ä¿®å¤æ€»ç»“:"
echo "   âœ… ç§»é™¤äº†æ‰€æœ‰å¯¹prompt_builderæ–¹æ³•çš„é”™è¯¯awaitè°ƒç”¨"
echo "   âœ… ä¿®å¤äº†query_with_runtimeæ–¹æ³•"
echo "   âœ… ä¿®å¤äº†diagnostic_queryæ–¹æ³•"
echo "   âœ… ä¿®å¤äº†æ™®é€šqueryæ–¹æ³•"
echo "   âœ… æ‰€æœ‰æç¤ºè¯æ„å»ºæ–¹æ³•ç°åœ¨éƒ½æ­£ç¡®åŒæ­¥è°ƒç”¨"
echo ""
echo "ğŸ”§ ç°åœ¨å¯ä»¥æ­£å¸¸ä½¿ç”¨çš„åŠŸèƒ½:"
echo "   1. å¢å¼ºæŸ¥è¯¢ (query-with-runtime) - é›†æˆè¿è¡Œæ—¶çŠ¶æ€å’Œè¯Šæ–­"
echo "   2. è¯Šæ–­åˆ†æ (diagnostics/analyze) - åŸºäºæ•…éšœæ ‘çš„å·¥ç¨‹è¯Šæ–­"
echo "   3. åŸºç¡€æŸ¥è¯¢ (query) - ä¼ ç»Ÿçš„RAGæŸ¥è¯¢"
echo "   4. æ•…éšœæ ‘æŸ¥çœ‹ (diagnostics/tree/{code}) - æŸ¥çœ‹å…·ä½“æ•…éšœæ ‘"
echo ""
echo "ğŸ“Š æœåŠ¡è¿è¡ŒçŠ¶æ€:"
echo "   PID: $PID"
echo "   æ—¥å¿—æ–‡ä»¶: /tmp/ros_docs_diag.log"
echo "   åœæ­¢å‘½ä»¤: kill $PID"
echo ""
echo "ğŸš€ å¿«é€Ÿæµ‹è¯•å‘½ä»¤:"
echo "   # å¸¦è¯Šæ–­çš„å¢å¼ºæŸ¥è¯¢"
echo "   curl -X POST http://localhost:8000/api/v1/ros/query-with-runtime \\"
echo "     -H 'Content-Type: application/json' \\"
echo "     -d '{\"query\":\"æœºå™¨äººå®‰å…¨åœæ­¢äº†æ€ä¹ˆåŠ\",\"top_k\":3,\"runtime_state\":{\"robot_id\":\"test\",\"errors\":[\"E201\"]}}'"
echo ""
echo "   # è¯Šæ–­åˆ†æ"
echo "   curl -X POST http://localhost:8000/api/v1/diagnostics/analyze \\"
echo "     -H 'Content-Type: application/json' \\"
echo "     -d '{\"error_codes\":[\"E201\"],\"runtime_state\":{\"robot_id\":\"test\",\"errors\":[\"E201\"],\"active_topics\":[\"/scan\", \"/cmd_vel\"]},\"include_detailed_analysis\":true}'"
echo ""
echo "âœ¨ æ‰€æœ‰å¼‚æ­¥è°ƒç”¨é—®é¢˜å·²ä¿®å¤!"